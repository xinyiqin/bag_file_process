# 摄食行为追踪 — 标注建议

用于评估跟踪指标（MOTA、IDF1 等）或做验证集，需要**带轨迹 ID 的标准标注**。下面从视频长度、标注内容、工具和流程给出可操作建议。

---

## 一、视频选取建议

### 1. 总时长与条数

| 用途           | 建议时长/数量        | 说明 |
|----------------|----------------------|------|
| 仅做跟踪评估   | 1～3 段，每段 1～3 分钟 | 覆盖不同场景即可 |
| 训练+评估      | 按你现有检测数据来   | 标注可只做“轨迹ID”，类别用检测模型 |
| 论文/严格对比 | 3～5 段，总 5～15 分钟 | 含遮挡、出画、多鱼同框等 |

- **不要太长**：单段 3～5 分钟足够，否则标注成本高、易疲劳。
- **要有代表性**：  
  - 不同光照、不同鱼数量（3～10 条）。  
  - 尽量包含：短暂遮挡、鱼出画再入画、摄食与普通状态都有。

### 2. 帧率与分辨率

- **帧率**：与最终应用一致（如 25/30 fps）。若原视频更高，可先抽帧再标（见下）。
- **分辨率**：与训练/推理一致（如 640×480），避免评估时再缩放带来偏差。

### 3. 是否抽帧标注（省时）

- **不抽帧**：每帧都标 → 指标最准，但工作量大。
- **抽帧**：例如每隔 1 帧或每 3 帧标一帧 → 标注量约为 1/2 或 1/3，评估时未标注帧可用线性插值生成“伪 GT”，或只对已标帧算指标。  
- **建议**：先做 1 段 1 分钟、每帧都标，看耗时；若太长再改为每 2 帧标一次。

---

## 二、标注内容（要标什么）

每条目标在**每一帧**（或你选中的帧）需要：

1. **边界框**：`x_min, y_min, x_max, y_max` 或 `x_center, y_center, w, h`（与工具/格式一致即可）。
2. **轨迹 ID（track_id）**：同一只鱼在所有帧里用**同一个整数 ID**，不同鱼不同 ID；鱼出画后再入画算**新 ID**。
3. **类别（可选）**：  
   - 若你要评估“摄食 vs 普通”的分类：每框再标类别（0=普通, 1=摄食）。  
   - 若只评估跟踪（MOTA、IDF1 等）：只标框 + ID 即可。

**规则建议**：

- 鱼被**完全遮挡超过约 1 秒**：遮挡期间不画框；重新出现时给**新 ID**（视为新轨迹）。
- 鱼**出画**：出画后不标；再入画给新 ID。
- **严重模糊/无法判断**的一帧：可不标该目标，或标框但后续评估时将该帧从 GT 中排除。

---

## 三、标注格式（便于评估）

跟踪评估常用 **MOT 格式**（每帧一个 txt，或一个 CSV 汇总）。

### 1. MOT 标准格式（每帧一个 txt）

目录结构示例：

```
gt/
  seqmaps/
    my_video.txt    # 内容就一行: name
  my_video/
    gt/
      gt.txt        # 所有帧的标注在一个文件里
    seqinfo.ini     # 视频信息
```

**gt.txt** 每行一框，空格分隔：

```
frame_id, track_id, x, y, w, h, conf, class
```

- `frame_id`：从 1 开始。  
- `track_id`：轨迹 ID。  
- `x, y, w, h`：左上角 x,y 和宽高（像素）。  
- `conf`：通常用 1。  
- `class`：1=行人等，你可用 1=鱼。  

示例一行（空格或逗号分隔均可）：

```
1,3,120,80,45,30,1,1
```
表示第 1 帧、轨迹 3、框 (120,80,45,30)、conf=1、class=1。

### 2. 简化版（单文件 CSV）

若暂时不用 MOT 官方评测脚本，可先做 CSV：

```csv
frame_id,track_id,x_min,y_min,x_max,y_max,class
1,1,100,50,180,120,0
1,2,200,80,260,140,1
2,1,105,52,185,122,0
...
```

- `class`：0=普通，1=摄食（若你做行为评估）。  
- 评估时再写个小脚本转成你用的格式（如 MOT 或 py-motmetrics 所需格式）。

---

## 四、推荐标注工具与流程

### 1. 工具选择

| 工具 | 特点 | 适用 |
|------|------|------|
| **CVAT** | 支持视频、多目标、track ID，导出 MOT/COCO | 首选，可自建或托管 |
| **Label Studio** | 灵活，可配视频+矩形+ID | 已有 LS 时可用 |
| **Dark Label** | 轻量、本地、支持跟踪标注 | 本地优先时 |
| **MOT 官方工具 / VATIC** | 专为 MOT 设计 | 严格按 MOT 评测时 |

推荐优先用 **CVAT**：  
- 新建 Project → Task，上传视频。  
- 选 “Segmentation” 或 “Object Detection”，在设置里开启 **Track**（给每个框设 track id）。  
- 标注时：同一只鱼在所有帧用同一个 track；可自动插值中间帧的框（半自动跟踪），再人工微调。

### 2. 标注流程（以 CVAT 为例）

1. **切片段**：从原始视频截 1～3 分钟片段，导出为 MP4。
2. **上传**：在 CVAT 建 Task，上传片段；设置帧率与分辨率一致。
3. **定规则**：  
   - 标签：如 `fish`；若标行为再加 `feeding` / `normal`。  
   - 开启 Track 模式，同一鱼同一 ID。
4. **逐帧或关键帧**：  
   - 从第一帧开始，为每只可见的鱼画框并分配 ID（1, 2, 3…）。  
   - 后续帧：尽量用 “Copy shape” 或跟踪插值，再移动/缩放框。  
   - 鱼出画：该 ID 不再画框；新出现的鱼给新 ID。
5. **导出**：导出为 MOT 格式或 COCO，再根据需要转成你脚本要的 CSV/gt.txt。

### 3. 质量控制

- **同一人**标同一段，避免 ID 规则不一致。  
- **抽查**：随机抽 50～100 帧，检查 ID 是否连续、框是否跟住目标。  
- **规则文档**：在项目里写 1 页“标注规则”（何时新 ID、遮挡/出画怎么标），标注者与评估脚本都按同一份规则来。

---

## 五、建议标注量汇总

- **视频**：1～3 段，每段 **1～3 分钟**，包含多鱼、遮挡、摄食与普通状态。  
- **帧**：若 30 fps、每段 2 分钟 → 约 3600 帧/段；可先做 1 段或抽帧（如每 2 帧标 1 帧）。  
- **格式**：MOT 的 gt.txt 或 CSV（frame_id, track_id, bbox, [class]）。  
- **工具**：CVAT（Track 模式）或 Dark Label 等，保证同一鱼同一 ID、出画/长遮挡用新 ID。  

这样得到的标注即可用于计算 MOTA、MOTP、IDF1、MT、IDSW、Frag 等指标；若每框带类别，还可评估摄食行为分类的精确率/召回率。

---

## 六、预标注 + 人工修正流程（推荐）

用现有模型先对视频做**预标注**，再**人工修正**少量错误（如错误 ID、错误状态），修正后的文件作为 **GT**，用于计算跟踪与识别指标。错误分两类：**track_id 错误**（ID 跟丢、ID 切换等）和 **class 错误**（摄食/普通判反）。下面先自动筛出可疑的 track_id，再把标注导入 CVAT 在视频上可视化并修改，最后导出为 GT CSV。

### 1. 导出预标注 CSV

对目标视频跑一次跟踪模型，把每帧的检测结果写成 CSV：

```bash
python3 run_feeding_track.py \
  --source fish_video.mp4 \
  --model best.pt \
  --export-pre-annotation output/pre_gt_fish_video.csv
```

生成的 **pre_gt_fish_video.csv** 列为：`frame_id`, `track_id`, `x_min`, `y_min`, `x_max`, `y_max`, `class`, `confidence`。其中 `class`：0=摄食，1=普通。

### 2. 自动检查可疑 track_id（先自动判断可能有误的地方）

运行检查脚本，会标出「可能有误」的轨迹，便于优先人工核对：

```bash
python3 check_pre_annotation.py output/pre_gt_fish_video.csv \
  --min-frames 30 \
  --out-flagged output/pre_gt_fish_video_flagged.csv \
  --out-report output/pre_annotation_report.txt
```

脚本会自动标出例如：

- **过短轨迹**：出现帧数 < 30 的 ID（可能是误检或碎片），列出这些 ID。
- **新 ID 突然出现**：前面几帧目标数已经较多且稳定，本帧突然多出一个新 ID（例如一开始约 10 条鱼，突然出现 ID 11），可能是 ID 分裂或误检。
- **同帧重复 ID**：同一帧里同一 track_id 出现多次（异常）。

终端会打印报告，`--out-flagged` 会在 CSV 中增加一列 `suspicious_reason`，便于在 Excel 里筛选出这些行先改。无法自动判断的（例如真正的 ID 切换、class 误判）留到下一步在 CVAT 里对着视频改。

### 3. 在 CVAT 中可视化并人工修正（推荐）

把预标注叠到原视频上，在 CVAT 里改 track_id、class 和框，导出后转回 GT CSV。

#### 3.1 将 CSV 转为 MOT 格式并打包

```bash
python3 export_csv_to_mot.py output/pre_gt_fish_video.csv \
  --video fish_video.mp4 \
  --out-dir output/mot_export \
  --zip output/mot_fish_video.zip
```

会生成 `output/mot_export/gt/gt.txt` 并打包为 `output/mot_fish_video.zip`（解压后仅含 **gt/** 文件夹）。MOT 采用单类别 **fish**，第 8 列恒为 1；**摄食/普通在导出后用脚本或模型按帧再算**。

#### 3.2 在 CVAT 中操作

详细步骤见 **[CVAT使用指南.md](CVAT使用指南.md)**，此处仅列要点：

1. **创建任务**：新建项目/任务，**Labels** 只建**一个** rectangle 标签 **fish**，上传**同一段视频**（与预标注对应的 `fish_video.mp4`）。
2. **导入标注**：任务内「Import annotations」，格式选 **MOT 1.1**，上传 `output/mot_fish_video.zip`。
3. **人工修正**（仅 track 与框）：  
   - **track_id**：ID 跟丢、ID 切换处用 **Merge tracks** 或删除错误轨迹后补画，使「同一只鱼同一 ID」。  
   - 框位置可拖动微调。  
   - **不**在 CVAT 里改摄食/普通（一条 track 只能一个 label）；类别在导出后由脚本或模型按帧再算。
4. **导出**：**Export annotations**，格式 **MOT 1.1**，下载 zip 并解压得到 gt.txt。

#### 3.3 将 CVAT 导出的 MOT 转回 GT CSV

```bash
python3 mot_to_gt_csv.py <CVAT 导出 zip 解压后的 gt.txt 路径> --out output/gt_fish_video.csv
```

得到的 CSV 列为 frame_id, track_id, x_min, y_min, x_max, y_max, **class**（此时 class=1 占位）。**摄食/普通**需再跑脚本或模型（如对每帧框跑分类），把 class 写成 0/1 后，方可给 `evaluate_tracking.py` 用。

### 4. 不借助 CVAT、仅用 Excel 修正（小量修正时）

若错误很少，也可以直接改 CSV：

- 用 **Excel** 或 **VS Code** 打开 `pre_gt_fish_video.csv`（或带 `suspicious_reason` 的 flagged 版本）。
- 按报告和 `suspicious_reason` 优先改可疑的 **track_id** 和 **class**。
- 另存为 `output/gt_fish_video.csv`，跳过 3.1～3.3，直接做下面的评估。

### 5. 用修正后的 GT 评估模型

安装依赖（若未装）：`pip install motmetrics`

```bash
python3 evaluate_tracking.py \
  --gt output/gt_fish_video.csv \
  --source fish_video.mp4 \
  --model best.pt
```

会输出跟踪指标（MOTA、MOTP、IDF1、IDSW、Frag、MT、FPS）和识别指标（摄食/普通的精确率、召回率、F1）。可选：`--iou-thresh 0.5`、`--save-pred output/pred_fish_video.csv`、`--tracker`（见下）。

### 5.1 多目标跟踪算法（可选）

预标注与评估均支持切换跟踪算法，通过 `--tracker` 指定：

| 算法 | 配置文件 | 说明 |
|------|----------|------|
| **ByteTrack** | `bytetrack.yaml` | 默认，速度较快，适合一般场景 |
| **BotSORT** | `botsort.yaml` | 带相机运动补偿与 Re-ID，更稳但更慢 |

**用法示例**：

- 预标注时指定跟踪器：
  ```bash
  python3 run_feeding_track.py --source fish_video.mp4 --tracker botsort.yaml --export-pre-annotation output/pre_gt_fish_video.csv
  ```
- 评估时指定跟踪器（须与预标注/应用时一致才可比对）：
  ```bash
  python3 evaluate_tracking.py --gt output/gt_fish_video.csv --source fish_video.mp4 --model best.pt --tracker botsort.yaml
  ```

不指定时默认使用 `bytetrack.yaml`。跟踪器配置与实现位于 `ultralytics/cfg/trackers/`、`ultralytics/trackers/`。

### 6. 流程小结

| 步骤 | 命令/操作 |
|------|------------|
| 1. 预标注 | `run_feeding_track.py --source <视频> --export-pre-annotation output/pre_gt_<名>.csv` |
| 2. 自动检查 | `check_pre_annotation.py output/pre_gt_<名>.csv --out-flagged output/flagged.csv --out-report output/report.txt` |
| **2b. 可选：批量合并 ID** | `merge_track_id.py output/pre_gt_<名>.csv --map 8:6 --out output/pre_gt_<名>_merged.csv`（见下） |
| 3a. 转 MOT | `export_csv_to_mot.py output/pre_gt_<名>.csv --video <视频> --out-dir output/mot_export --zip output/mot.zip` |
| 3b. CVAT 修正（https://app.cvat.ai/） | （建议在这一步之前通过2b步骤确保鱼的id数量=鱼的数量）创建任务并上传同一视频 → 导入 MOT zip → 在视频上改 track/框 → 导出 MOT |
| 3c. MOT 转 GT CSV | `mot_to_gt_csv.py <CVAT 导出的 gt.txt> --out output/gt_<名>.csv` |
| 4. 评估 | `evaluate_tracking.py --gt output/gt_<名>.csv --source <视频> --model best.pt`（可加 `--tracker botsort.yaml`，见 5.1） |

若只做少量修正，可在步骤 2 之后直接用 Excel 改 CSV 并另存为 GT，跳过 3a～3c。

**建议**：当「某条鱼跟丢后以新 id 再出现」时（例如本该一直是 6，中间跟丢后变成 8），在 CVAT 里很难把整条轨迹的 id 批量改回 6。**建议在 CSV 里先用 `merge_track_id.py` 把 8 批量改成 6，再转 MOT 导入 CVAT**，这样 CVAT 里只需做框和轨迹微调，不必在 CVAT 里做 Merge 或逐帧改 id。

**批量合并 ID 用法**（步骤 2b）：
```bash
# 把 track_id=8 全部改为 6（同一条鱼 6 跟丢后 reappear 成 8，合并回 6）
python3 merge_track_id.py output/pre_gt_fish_video.csv --map 8:6 --out output/pre_gt_fish_video_merged.csv

# 多组：把 8 和 10 都改为 6
python3 merge_track_id.py output/pre_gt_fish_video.csv --map 8:6 --map 10:6 --out output/pre_gt_fish_video_merged.csv
```
之后用 `pre_gt_fish_video_merged.csv` 做 3a 转 MOT、导入 CVAT。



### 7. 参考流程

1.预标注
```bash
python3 run_feeding_track.py   --source fish_video.mp4   --model best.pt   --export-pre-annotation output/pre_gt_fish_video.csv
```

2.自动检查
```bash
python3 check_pre_annotation.py output/pre_gt_fish_video.csv --out-flagged output/pre_gt_fish_video_flagged.csv --min-frames 30
```

3.转为mot格式
```bash
python3 export_csv_to_mot.py output/pre_gt_fish_video.csv --video fish_video.mp4 --out-dir output/mot_export --zip output/mot_fish_video.zip --keyframe-every 10
```

4.批量把id为8改为id为6(对于目标跟丢的情况)
```bash
python3 merge_track_id.py output/pre_gt_fish_video.csv --map 8:6 --out output/pre_gt_fish_video_merged.csv
```


5.
在CVAT里做人工修改（比如补帧，比如前面目标跟丢的时候有某一帧其实没有追踪到）
比如鱼重叠的时候识别框有问题

6.最后导出MOT 1.1格式，得到其中的gt.txt文件，转回gt.csv文件
```bash
python3 mot_to_gt_csv.py output/gt.txt --out output/gt_fish_video.csv
```

7.进行评估

